{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_state": "idle",
   "id": "59902a5f-b3d3-41b5-9712-c7192be7fefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T12:26:48.062188Z",
     "iopub.status.busy": "2025-11-07T12:26:48.061653Z",
     "iopub.status.idle": "2025-11-07T12:26:48.065682Z",
     "shell.execute_reply": "2025-11-07T12:26:48.065046Z",
     "shell.execute_reply.started": "2025-11-07T12:26:48.062159Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import asyncio\n",
    "import argparse\n",
    "from boto3.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_state": "idle",
   "id": "4d642560-b052-40b8-bbd4-a5d0c644fdf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T12:26:49.323467Z",
     "iopub.status.busy": "2025-11-07T12:26:49.322982Z",
     "iopub.status.idle": "2025-11-07T12:26:49.330343Z",
     "shell.execute_reply": "2025-11-07T12:26:49.329267Z",
     "shell.execute_reply.started": "2025-11-07T12:26:49.323430Z"
    }
   },
   "outputs": [],
   "source": [
    "async def invoke_agent(question):\n",
    "    boto_session = Session()\n",
    "    region_name = boto3.Session().region_name\n",
    "\n",
    "\n",
    "    #SSM을 활용해서 Bedrock AgenticCore ARN 가져오기\n",
    "    ssm_client = boto_session.client('ssm', region_name=region_name)\n",
    "    agent_arn_response = ssm_client.get_parameter(\n",
    "        Name=\"/basic_server/runtime_iam/agent_arn\"\n",
    "    )\n",
    "    agentcore_client = boto3.client('bedrock-agentcore', region_name=region_name)\n",
    "\n",
    "    \n",
    "    #Streaming으로 Bedrock AgenticCore Application 호출하기\n",
    "    loop = asyncio.get_event_loop()\n",
    "    response = await loop.run_in_executor(\n",
    "        None,\n",
    "        lambda: agentcore_client.invoke_agent_runtime(\n",
    "            agentRuntimeArn=agent_arn_response[\"Parameter\"][\"Value\"],\n",
    "            qualifier=\"DEFAULT\",\n",
    "            payload=json.dumps({\"input_data\": question})\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #응답을 객체로 받은뒤 계속적으로 오는 streaming 결과 출력\n",
    "    for line in response['response'].iter_lines():\n",
    "        if line and line.startswith(b'data: '):\n",
    "            data = json.loads(line[6:].decode('utf-8'))\n",
    "            if data['type'] == 'stream':\n",
    "                print(data['content'], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_state": "idle",
   "id": "ac5a0ba4-9390-414d-a1c9-ee5d8a20973f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T12:26:50.148398Z",
     "iopub.status.busy": "2025-11-07T12:26:50.148029Z",
     "iopub.status.idle": "2025-11-07T12:27:02.596775Z",
     "shell.execute_reply": "2025-11-07T12:27:02.596012Z",
     "shell.execute_reply.started": "2025-11-07T12:26:50.148362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발을 위한 오픈소스 프레임워크입니다.\n",
      "\n",
      "## 주요 특징\n",
      "\n",
      "### 1. **체인(Chain) 기반 구조**\n",
      "- 여러 컴포넌트를 연결하여 복잡한 워크플로우 구성\n",
      "- 단계별 처리를 통한 체계적인 작업 수행\n",
      "\n",
      "### 2. **핵심 컴포넌트**\n",
      "\n",
      "**프롬프트 템플릿 (Prompt Templates)**\n",
      "```python\n",
      "from langchain import PromptTemplate\n",
      "\n",
      "template = \"다음 질문에 {language}로 답해주세요: {question}\"\n",
      "prompt = PromptTemplate(\n",
      "    input_variables=[\"language\", \"question\"],\n",
      "    template=template\n",
      ")\n",
      "```\n",
      "\n",
      "**LLM 통합**\n",
      "- OpenAI GPT, Anthropic Claude, Hugging Face 모델 등 지원\n",
      "- 다양한 모델을 통일된 인터페이스로 사용\n",
      "\n",
      "**메모리 관리**\n",
      "- 대화 히스토리 저장 및 관리\n",
      "- 컨텍스트 유지를 통한 연속적인 대화\n",
      "\n",
      "### 3. **주요 기능들**\n",
      "\n",
      "**문서 처리**\n",
      "- PDF, 웹페이지, 텍스트 파일 등 다양한 형식 지원\n",
      "- 문서 분할, 임베딩, 벡터 저장소 연동\n",
      "\n",
      "**에이전트 (Agents)**\n",
      "- 도구를 사용하여 자율적으로 작업 수행\n",
      "- 웹 검색, 계산기, API 호출 등 외부 도구 활용\n",
      "\n",
      "**RAG (Retrieval-Augmented Generation)**\n",
      "- 외부 지식베이스와 연동\n",
      "- 실시간 정보 검색 및 활용\n",
      "\n",
      "## 사용 사례\n",
      "\n",
      "1. **챗봇 개발**\n",
      "2. **문서 요약 및 분석**\n",
      "3. **질의응답 시스템**\n",
      "4. **코드 생성 도구**\n",
      "5. **데이터 분석 자동화**\n",
      "\n",
      "## 장점\n",
      "\n",
      "- **모듈화**: 재사용 가능한 컴포넌트\n",
      "- **확장성**: 다양한 LLM과 도구 지원\n",
      "- **커뮤니티**: 활발한 개발자 생태계\n",
      "- **문서화**: 풍부한 예제와 가이드\n",
      "\n",
      "LangChain은 LLM의 복잡한 기능들을 쉽게 구현할 수 있게 해주는 강력한 도구로, AI 애플리케이션 개발의 진입 장벽을 크게 낮춰줍니다.\n"
     ]
    }
   ],
   "source": [
    "await invoke_agent(\"langchain에 대해 설명해 주세요\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a97cc-6b18-4442-853c-d576929be592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
